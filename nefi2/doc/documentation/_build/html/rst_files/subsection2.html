

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>algorithms &mdash; nefi 2.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="nefi 2.0 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> nefi
          

          
          </a>

          
            
            
              <div class="version">
                2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quick_Start_Guide_for_users.html">Quick Start Guide for users</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quick_Start_Guide_for_developers.html">Quick Start Guide for developers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Development.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="Technologies.html">Dependencies</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">nefi</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>algorithms</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/rst_files/subsection2.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="algorithms">
<h1>algorithms<a class="headerlink" href="#algorithms" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-model.algorithms.constant_threshold">
<span id="constant-threshold"></span><h2>constant_threshold<a class="headerlink" href="#module-model.algorithms.constant_threshold" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.constant_threshold.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.constant_threshold.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.constant_threshold.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Constant Threshold implementation.</p>
<dl class="method">
<dt id="model.algorithms.constant_threshold.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.constant_threshold.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Constant thresholding as described in opencv docs.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.grabcut_dilation_erosion_otsu">
<span id="grabcut-dilation-erosion-otsu"></span><h2>grabcut_dilation_erosion_otsu<a class="headerlink" href="#module-model.algorithms.grabcut_dilation_erosion_otsu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.grabcut_dilation_erosion_otsu.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Grabcut - Dilation Erosion Otsu algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.apply_mask_to_image">
<code class="descname">apply_mask_to_image</code><span class="sig-paren">(</span><em>mask</em>, <em>image</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.apply_mask_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the segmented image based on the original image and the
mask.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : An input image which is not altered</div>
<div class="line"><em>mask</em> : A mask containing foreground and background information</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>A segmented image</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.erosion_dilation_marker">
<code class="descname">erosion_dilation_marker</code><span class="sig-paren">(</span><em>image</em>, <em>erosion_iterations=2</em>, <em>dilation_iterations=1</em>, <em>threshold_strategy=&lt;function otsus_threshold&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.erosion_dilation_marker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies morphological transformations to obtain the marker. The areas
likely to be foreground are obtained by erosion. The areas likely to
be background are obtained by dilation.
The final marker is obtained by adding likely background to likely
foreground where areas not part of either are considered undecided.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><ul class="first last simple">
<li>threshold_image* : A properly thresholded image</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd>A marker subdividing image regions into likely foreground, likely
background and undecided pixels</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.grabcut">
<code class="descname">grabcut</code><span class="sig-paren">(</span><em>image</em>, <em>marker</em>, <em>grabcut_iterations=5</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.grabcut" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies opencv&#8217;s grabcut method iteratively to an input image. An
initial marker containing preliminary information on whether a pixel is
foreground, background or probably background serves as additional
input. The initial marker can be based on user input (color-picking),
or can be constructed with an automatic marker strategy. The marker is
updated and improved by the grabcut method iteratively. Finally, the
marker is used to obtain a mask classifying every pixel into foreground
or background.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : An input image which is not altered</div>
<div class="line"><em>marker</em>: A marer suitable for use with opencv&#8217;s grabcut</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>A mask image classifying every pixel into foreground or background</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.otsus_threshold">
<code class="descname">otsus_threshold</code><span class="sig-paren">(</span><em>image</em>, <em>threshold_value=0</em>, <em>threshold_type=1L</em>, <em>**_</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.otsus_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_dilation_erosion_otsu.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Watershed algorithm from the opencv package to the current
image with the help of marker based ob dilation, erosion and
adaptive threshold.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.adaptive">
<span id="adaptive"></span><h2>adaptive<a class="headerlink" href="#module-model.algorithms.adaptive" title="Permalink to this headline">¶</a></h2>
<p>(from opencv docs)
Adaptive Thresholding.
Global threshold value may not be good in all the conditions where image has
different lighting conditions in different areas. In that case, we go for
adaptive thresholding. In this, the algorithm calculate the threshold for a
small regions of the image. So we get different thresholds for different
regions of the same image and it gives us better results for images with
varying illumination.</p>
<dl class="class">
<dt id="model.algorithms.adaptive.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.adaptive.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.adaptive.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Adaptive Threshold implementation.</p>
<dl class="method">
<dt id="model.algorithms.adaptive.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.adaptive.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Adaptive thresholding as described in opencv docs.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.watershed_distance_transform_otsu">
<span id="watershed-distance-transform-otsu"></span><h2>watershed_distance_transform_otsu<a class="headerlink" href="#module-model.algorithms.watershed_distance_transform_otsu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.watershed_distance_transform_otsu.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Watershed - Distance Transform Otsu implementation</p>
<dl class="method">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody.apply_mask_to_image">
<code class="descname">apply_mask_to_image</code><span class="sig-paren">(</span><em>mask</em>, <em>image</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody.apply_mask_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the segmented image based on the original image and the mask.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
mask: A mask containing foreground and background information</dd>
<dt>Returns:</dt>
<dd>A segmented image</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody.distance_transform_dilation_marker">
<code class="descname">distance_transform_dilation_marker</code><span class="sig-paren">(</span><em>image, opening_iterations=2, dilation_iterations=1, kernel=array([[1, 1, 1],        [1, 1, 1],        [1, 1, 1]], dtype=uint8), distance_factor=0.7, threshold_strategy=&lt;function otsus_threshold&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody.distance_transform_dilation_marker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies morphological transformation, i.e. morphological opening using a kernel to obtain the areas
of the image likely to be foreground. The areas likely to be background are obtained by dilation.
The final marker is obtained by adding likely background to likely foreground where areas not part of
either are considered undecided.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>threshold_image: A properly thresholded image</dd>
<dt>Returns:</dt>
<dd>A marker subdividing image regions into likely foreground, likely background and undecided pixels</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody.otsus_threshold">
<code class="descname">otsus_threshold</code><span class="sig-paren">(</span><em>image</em>, <em>threshold_value=0</em>, <em>threshold_type=1L</em>, <em>**_</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody.otsus_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Watershed algorithm from the opencv package to the current
image with the help of marker based ob dilation, erosion and
adaptive threshold.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_distance_transform_otsu.AlgBody.watershed">
<code class="descname">watershed</code><span class="sig-paren">(</span><em>image</em>, <em>marker</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_distance_transform_otsu.AlgBody.watershed" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies opencv&#8217;s watershed method iteratively to an input image. An initial marker containing
preliminary information on which pixels are foreground serves as additional input.
The initial marker can be based on user input (color-picking), or can be constructed
with an automatic marker strategy. The marker decides from which pixels the flooding
in the watershed method may start. Finally, the marker is used to obtain a mask
classifying every pixel into foreground or background.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
marker: A marer suitable for use with opencv&#8217;s grabcut
iterations: The number of iterations grabcut may update the marker</dd>
<dt>Returns:</dt>
<dd>A mask image classifying every pixel into foreground or background</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.connected_component_filter">
<span id="connected-component-filter"></span><h2>connected_component_filter<a class="headerlink" href="#module-model.algorithms.connected_component_filter" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.connected_component_filter.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.connected_component_filter.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.connected_component_filter.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Connected Component Filter algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.connected_component_filter.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.connected_component_filter.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a filter which filters a graph for connected components
according to a threshold value.
To decide whether or not a connected component is removed the component
size and the threshold value are used together in a logical operation.</p>
<dl class="docutils">
<dt>Example: Remove all connected components of size strictly</dt>
<dd>smaller than 3</dd>
</dl>
<p>Example: Remove all connected components of size greater or equal to 5
Example: Remove all connected components of size exaclty 7</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : A list which contains the image and the graph</div>
</div>
</dd>
<dt>Raises:</dt>
<dd><div class="first last line-block">
<div class="line"><em>KeyError</em> : Filtering failed because the
threshold connected component size is negative</div>
</div>
</dd>
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>graph</em> : A filtered networkx graph</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.med_blur">
<span id="med-blur"></span><h2>med_blur<a class="headerlink" href="#module-model.algorithms.med_blur" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.med_blur.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.med_blur.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.med_blur.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Median Blur algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.med_blur.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.med_blur.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Median Blur algorithm from the opencv package to the current
image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.simple_cycle">
<span id="simple-cycle"></span><h2>simple_cycle<a class="headerlink" href="#module-model.algorithms.simple_cycle" title="Permalink to this headline">¶</a></h2>
<p>(from networkx docs)
Biconnected components are maximal subgraphs such that the removal of a node
(and all edges incident on that node) will not disconnect the subgraph. Note
that nodes may be part of more than one biconnected component. Those nodes are
articulation points, or cut vertices. The removal of articulation points will
increase the number of connected components of the graph.</p>
<dl class="class">
<dt id="model.algorithms.simple_cycle.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.simple_cycle.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.simple_cycle.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Simple cycle filter implementation.</p>
<dl class="staticmethod">
<dt id="model.algorithms.simple_cycle.AlgBody.draw_edges">
<em class="property">static </em><code class="descname">draw_edges</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.simple_cycle.AlgBody.draw_edges" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw edges into current image instance</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list containing image array and Graph object</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="staticmethod">
<dt id="model.algorithms.simple_cycle.AlgBody.draw_nodes">
<em class="property">static </em><code class="descname">draw_nodes</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.simple_cycle.AlgBody.draw_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw nodes as rectangle into current image instance</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list containing image array and Graph object</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.simple_cycle.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.simple_cycle.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>By using a generator of sets of nodes, one set for each biconnected
component of the graph(biconnected_components) we remove all vertices
which do not belong to a cycle (degree greater than two). The output is
a graph including only biconnected components.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list containing image array and Graph object</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.edge_attribute_filter">
<span id="edge-attribute-filter"></span><h2>edge_attribute_filter<a class="headerlink" href="#module-model.algorithms.edge_attribute_filter" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.edge_attribute_filter.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.edge_attribute_filter.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.edge_attribute_filter.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Edge attribute filter algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.edge_attribute_filter.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.edge_attribute_filter.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a filter which filters a graph for a certain edge attribute
according to a threshold value.
To decide whether or not an edge is removed the attribute value and
the threshold value are used together in a logical operation.</p>
<p>Example: Remove all edges with length strictly smaller than 10.5
Example: Remove all edges with width greater or equal to 5
Example: Remove all edges with length exaclty 7</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>input</em> : a list which contains the image and the graph</div>
</div>
</dd>
<dt>Raises:</dt>
<dd><div class="first last line-block">
<div class="line"><em>KeyError</em> : Filtering failed because attribute is not present
in the graph as an edge attribute</div>
</div>
</dd>
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>graph</em> : A filtered networkx graph</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.largest_connected">
<span id="largest-connected"></span><h2>largest_connected<a class="headerlink" href="#module-model.algorithms.largest_connected" title="Permalink to this headline">¶</a></h2>
<p>(taken from NEFI1)
Implementation of an algorithm which filters a graph for connected components
and keeps only the largest of them, e.g remove all connected components except
the 4 largest.</p>
<dl class="class">
<dt id="model.algorithms.largest_connected.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.largest_connected.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.largest_connected.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Keep only largest connected component algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.largest_connected.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.largest_connected.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Keep only largest connected component from nefi1.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list containing image array and Graph object</div>
</div>
</dd>
<dt>Raises:</dt>
<dd><div class="first last line-block">
<div class="line"><em>ValueError</em> : means filtering failed due to the number
of components not to be removed is negative.</div>
</div>
</dd>
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>graph</em> : a filtered networkx Graph</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms._alg">
<span id="alg"></span><h2>_alg<a class="headerlink" href="#module-model.algorithms._alg" title="Permalink to this headline">¶</a></h2>
<p>A module which contains all necessary information&#8217;s and features to create
an additional implementation of algorithms.
To contribute an algorithm implementation the contributor is needs to create
a seperate &lt;algorithm_name&gt;.py in the algorithms folder. In &lt;algorithm_name&gt;.py
he needs to create a class &#8220;class AlgBody(Algorithm):&#8221; which inherits from
Algorithm.
In order to give the ext_loader the possibility to dynamically invoke the
algorithm definition, the contributor also needs to override the
methods: process(self, image), get_name(self) and belongs_to(self).
Additional UI input for the algorithm can be specified by creating
IntegerSlider, FloatSlider, CheckBox or DropDown objects. These object
instances need to be created by the constructor method __init__(self) of the
algorithm implementation. E.g. we create a IntegerSlider in __init__(self)
by calling the constructor of IntegerSlider and binding it to slider1 with
&#8220;slider1 = IntegerSlider(self, &#8220;slider1&#8221;, 0, 10, 1, 0)&#8221; (see the IntegerSlider
definition for further information)</p>
<dl class="class">
<dt id="model.algorithms._alg.Algorithm">
<em class="property">class </em><code class="descclassname">model.algorithms._alg.</code><code class="descname">Algorithm</code><a class="headerlink" href="#model.algorithms._alg.Algorithm" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="model.algorithms._alg.Algorithm.belongs">
<code class="descname">belongs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.belongs" title="Permalink to this definition">¶</a></dt>
<dd><p>Identifies the category to which this algorithm implementation is assoc
iated with. Therefore you the contributor returns a string yielding the
name of the associated category. E.g. we have an algorithm &#8220;blur&#8221; which
is created through implementing the abstract class Algorithm. In &#8220;blur&#8221;
we override the belongs method to return &#8220;preprocessing&#8221; to associate
the &#8220;blur&#8221; algorithm instance with the category &#8220;preprocessing&#8221;.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><div class="first line-block">
<div class="line"><em>self.parent</em>: The string identifier to which category this</div>
</div>
<p class="last">algorithm belongs to</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.find_ui_element">
<code class="descname">find_ui_element</code><span class="sig-paren">(</span><em>name</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.find_ui_element" title="Permalink to this definition">¶</a></dt>
<dd><p>This method helps the json parser to find the ui elements
with the given name</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><a href="#id1"><span class="problematic" id="id2">|</span></a>name: name of the ui element we are looking for</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.get_icon">
<code class="descname">get_icon</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.get_icon" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>icon_path</em>: The path to the icon to be used</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns the name of the implemented algorithm. E.g. int case the contributor
is implementing a &#8220;watershed&#8221; algorithm, his get_name method should return &#8220;watershed&#8221;.
By default this method raises an error if the user is not overriding his own get_name
method.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>self.name</em>: The name of the algorithm specified in this implementation.</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>input_data</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Contains the logic of the implemented algorithm. While computing
the pipeline each algorithm will be called with its process method
giving the output image from the previous algorithm processed in
the pipeline The images are used to draw the result of each algorithm
in the left section of the UI. Therefore the contributor should return
an image itself at the end of this method.
By default this method raises an error if the user is not overriding
his own process
method.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first line-block">
<div class="line"><em>input_data</em>: a tuple which contains all relevant arguments found in</div>
</div>
<p class="last">the results of the previous processed algorithm. As common in the
pipeline pattern, the successors always get called with the
information the predecessor created.
The first element in input_data should always be image array,
the second element is reserved for graph. This is why algorithm
process methods operate on args indeces (args[0] or args[1]).
Please consider this in case you decide to add an algorithm which
produces something different than an image array or networkx graph
object.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.report_pip">
<code class="descname">report_pip</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.report_pip" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a dictionary which contains all relevant algorithm
information and returns it to the pipeline along with the algorithm
name. The pipeline needs this information to create a json
representation of the algorithm. It will encode the dic as following:
E.g. blur : {&#8220;type&#8221; : &#8220;preprocessing&#8221;, &#8220;kernelsize&#8221; : 2.5}
The encoding of the dic to json will be done by the pipeline which
collects the dictionary of each algorithm in the processing list.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>self.name, collections.OrderedDict</em> (list): A tuple consisting
of the name of the algorithm and the dic containing all relevant
information about the algorithm which need to be stored on the
filesystem for the pipeline.json.</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.set_icon">
<code class="descname">set_icon</code><span class="sig-paren">(</span><em>icon_path</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.set_icon" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>icon_path</em>: The path to the icon to be used</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.set_modified">
<code class="descname">set_modified</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.set_modified" title="Permalink to this definition">¶</a></dt>
<dd><p>Set modified to True</p>
</dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.set_store_image">
<code class="descname">set_store_image</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.set_store_image" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms._alg.Algorithm.unset_modified">
<code class="descname">unset_modified</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.Algorithm.unset_modified" title="Permalink to this definition">¶</a></dt>
<dd><p>Set modified to False</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="model.algorithms._alg.CheckBox">
<em class="property">class </em><code class="descclassname">model.algorithms._alg.</code><code class="descname">CheckBox</code><span class="sig-paren">(</span><em>name</em>, <em>default</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.CheckBox" title="Permalink to this definition">¶</a></dt>
<dd><p>A class defining a Checkbox of type boolean to display in the algorithm
detail section of the UI. After calling the CheckBox constructor, the
program automatically creates ui widgets as well as qt slots and signals to
connect this checkbox with the UI.</p>
<dl class="method">
<dt id="model.algorithms._alg.CheckBox.set_value">
<code class="descname">set_value</code><span class="sig-paren">(</span><em>arg1</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.CheckBox.set_value" title="Permalink to this definition">¶</a></dt>
<dd><p>The set_value method is used by the UI and the batch-mode of NEFI as an
input source of selected values for this particular checkbox instance.
The &#64;pyqtSlot(bool) decoration declares this method as as QT-Slot. To
get more information about Slots and Signals in QT read about it in the
official QT documentation.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first line-block">
<div class="line"><em>arg1</em>: the boolean value selected in the ui or the pipeline in</div>
</div>
<p class="last">batch-mode</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="model.algorithms._alg.DropDown">
<em class="property">class </em><code class="descclassname">model.algorithms._alg.</code><code class="descname">DropDown</code><span class="sig-paren">(</span><em>name</em>, <em>options</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.DropDown" title="Permalink to this definition">¶</a></dt>
<dd><p>A class defining a DropDown menu of type string to display in the algorithm
detail section of the UI. After calling the DropDown constructor, the
program automatically creates ui widgets as well as qt slots and signals to
connect this DropDown with the UI.</p>
<dl class="method">
<dt id="model.algorithms._alg.DropDown.set_value">
<code class="descname">set_value</code><span class="sig-paren">(</span><em>arg1</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.DropDown.set_value" title="Permalink to this definition">¶</a></dt>
<dd><p>The set_value method is used by the UI and the batch-mode of NEFI as an
inputsource of selected values for this particular DropDown instance.
The &#64;pyqtSlot(str) decoration declares this method as as QT-Slot. To
get more information about Slots and Signals in QT read about it in the
official QT documentation.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first line-block">
<div class="line"><em>arg1</em>: the string value selected in the ui or the pipeline in</div>
</div>
<p class="last">batch-mode</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="model.algorithms._alg.FloatSlider">
<em class="property">class </em><code class="descclassname">model.algorithms._alg.</code><code class="descname">FloatSlider</code><span class="sig-paren">(</span><em>name</em>, <em>lower</em>, <em>upper</em>, <em>step_size</em>, <em>default</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.FloatSlider" title="Permalink to this definition">¶</a></dt>
<dd><p>A class defining a slider of type float to display in the algorithm detail
section of the UI. After calling the FloatSlider constructor, the program
automatically creates ui widgets as well as qt slots and signals to connect
this slider with the UI.</p>
<dl class="method">
<dt id="model.algorithms._alg.FloatSlider.set_value">
<code class="descname">set_value</code><span class="sig-paren">(</span><em>arg1</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.FloatSlider.set_value" title="Permalink to this definition">¶</a></dt>
<dd><p>The set_value method is used by the UI and the batch-mode of NEFI as an
input source of selected values for this particular slider instance.
The &#64;pyqtSlot(int) decoration declares this method as as QT-Slot.
To get more information about Slots and Signals in QT read about it in
the official QT documentation.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first line-block">
<div class="line"><em>arg1</em>: the integer value selected in the ui or the pipeline in</div>
</div>
<p class="last">batch-mode</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="model.algorithms._alg.IntegerSlider">
<em class="property">class </em><code class="descclassname">model.algorithms._alg.</code><code class="descname">IntegerSlider</code><span class="sig-paren">(</span><em>name</em>, <em>lower</em>, <em>upper</em>, <em>step_size</em>, <em>default</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.IntegerSlider" title="Permalink to this definition">¶</a></dt>
<dd><p>A class defining a slider of type int to display in the algorithm detail
section of the UI. After calling the IntegerSlider constructor, the program
automatically creates ui widgets as wellas qt slots and signals to connect
this slider with the UI.</p>
<dl class="method">
<dt id="model.algorithms._alg.IntegerSlider.set_value">
<code class="descname">set_value</code><span class="sig-paren">(</span><em>arg1</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._alg.IntegerSlider.set_value" title="Permalink to this definition">¶</a></dt>
<dd><p>The set_value method is used by the UI and the batch-mode of NEFI as
an input source of selected values for this particular slider instance.
The &#64;pyqtSlot(int) decoration declares this method as as QT-Slot.
To get more information about Slots and Signals in QT read about it in
the official QT documentation.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first line-block">
<div class="line"><em>arg1</em>: the integer value selected in the ui or the pipeline in</div>
</div>
<p class="last">batch-mode</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.fast_nl_denoise">
<span id="fast-nl-denoise"></span><h2>fast_nl_denoise<a class="headerlink" href="#module-model.algorithms.fast_nl_denoise" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.fast_nl_denoise.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.fast_nl_denoise.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.fast_nl_denoise.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Fast nl Means Denoising algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.fast_nl_denoise.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.fast_nl_denoise.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Fast nl Means Denoising algorithm from the opencv package to
the current image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.grabcut_distance_transform_otsu">
<span id="grabcut-distance-transform-otsu"></span><h2>grabcut_distance_transform_otsu<a class="headerlink" href="#module-model.algorithms.grabcut_distance_transform_otsu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.grabcut_distance_transform_otsu.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Grabcut - Distance Transform Otsu algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody.apply_mask_to_image">
<code class="descname">apply_mask_to_image</code><span class="sig-paren">(</span><em>mask</em>, <em>image</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody.apply_mask_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the segmented image based on the original image and the
mask.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : An input image which is not altered</div>
<div class="line"><em>mask</em> : A mask containing foreground and background information</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>A segmented image</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody.distance_transform_dilation_marker">
<code class="descname">distance_transform_dilation_marker</code><span class="sig-paren">(</span><em>image, opening_iterations=2, dilation_iterations=1, kernel=array([[1, 1, 1],        [1, 1, 1],        [1, 1, 1]], dtype=uint8), distance_factor=0.7, threshold_strategy=&lt;function otsus_threshold&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody.distance_transform_dilation_marker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies morphological transformation, i.e. morphological opening using
a kernel to obtain the areas of the image likely to be foreground. The
areas likely to be background are obtained by dilation.
The final marker is obtained by adding likely background to likely
foreground where areas not part of either are considered undecided.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><em>threshold_image</em> : A properly thresholded image</dd>
<dt>Returns:</dt>
<dd>A marker subdividing image regions into likely foreground, likely
background and undecided pixels</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody.grabcut">
<code class="descname">grabcut</code><span class="sig-paren">(</span><em>image</em>, <em>marker</em>, <em>grabcut_iterations=5</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody.grabcut" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies opencv&#8217;s grabcut method iteratively to an input image. An
initial marker containing preliminary information on whether a pixel
is foreground, background or probably background serves as additional
input. The initial marker can be based on user input (color-picking),
or can be constructed with an automatic marker strategy. The marker is
updated and improved by the grabcut method iteratively. Finally, the
marker is used to obtain a mask classifying every pixel into
foreground or background.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : An input image which is not altered</div>
<div class="line"><em>marker</em> : A marer suitable for use with opencv&#8217;s grabcut</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>A mask image classifying every pixel into foreground or background</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody.otsus_threshold">
<code class="descname">otsus_threshold</code><span class="sig-paren">(</span><em>image</em>, <em>threshold_value=0</em>, <em>threshold_type=1L</em>, <em>**_</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody.otsus_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.grabcut_distance_transform_otsu.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.grabcut_distance_transform_otsu.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Watershed algorithm from the opencv package to the current
image with the help of marker based ob dilation, erosion and
adaptive threshold.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.gauss_blur">
<span id="gauss-blur"></span><h2>gauss_blur<a class="headerlink" href="#module-model.algorithms.gauss_blur" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.gauss_blur.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.gauss_blur.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.gauss_blur.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Gaussian Blur algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.gauss_blur.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.gauss_blur.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Gaussian Blur algorithm from the opencv package to the current
image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.blur">
<span id="blur"></span><h2>blur<a class="headerlink" href="#module-model.algorithms.blur" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.blur.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.blur.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.blur.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Blur algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.blur.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.blur.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Blur algorithm from the opencv package to the chosen colour
channels of the current image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms._thread">
<span id="thread"></span><h2>_thread<a class="headerlink" href="#module-model.algorithms._thread" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms._thread.myThread">
<em class="property">class </em><code class="descclassname">model.algorithms._thread.</code><code class="descname">myThread</code><span class="sig-paren">(</span><em>threadID</em>, <em>name</em>, <em>counter</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._thread.myThread" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">threading.Thread</span></code></p>
<dl class="method">
<dt id="model.algorithms._thread.myThread.run">
<code class="descname">run</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._thread.myThread.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="model.algorithms._thread.print_time">
<code class="descclassname">model.algorithms._thread.</code><code class="descname">print_time</code><span class="sig-paren">(</span><em>threadName</em>, <em>delay</em>, <em>counter</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._thread.print_time" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-model.algorithms._utility">
<span id="utility"></span><h2>_utility<a class="headerlink" href="#module-model.algorithms._utility" title="Permalink to this headline">¶</a></h2>
<p>Various help functions for processing results.</p>
<dl class="function">
<dt id="model.algorithms._utility.check_operator">
<code class="descclassname">model.algorithms._utility.</code><code class="descname">check_operator</code><span class="sig-paren">(</span><em>operator</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._utility.check_operator" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts the string value of the DropDown element in operator object</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>operator</em> : DropDown object from the algorithm class</div>
</div>
</dd>
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>op_object</em>: operator object converted</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="model.algorithms._utility.draw_edges">
<code class="descclassname">model.algorithms._utility.</code><code class="descname">draw_edges</code><span class="sig-paren">(</span><em>img</em>, <em>graph</em>, <em>col=(0</em>, <em>0</em>, <em>255)</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._utility.draw_edges" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw network edges on the input image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>img</em> : Input image where edges are drawn</div>
<div class="line"><em>graph</em> : Input graph containing the edges</div>
</div>
</dd>
<dt>Kwargs:</dt>
<dd><div class="first last line-block">
<div class="line"><em>col</em> : colour for drawing</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>Input image img with nodes drawn into it</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="model.algorithms._utility.draw_graph">
<code class="descclassname">model.algorithms._utility.</code><code class="descname">draw_graph</code><span class="sig-paren">(</span><em>image</em>, <em>graph</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._utility.draw_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw the graph on the image by traversing the graph structure.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : the image where the graph needs to be drawn</div>
<div class="line"><em>graph</em> : the <a href="#id3"><span class="problematic" id="id4">*</span></a>.txt file containing the graph information</div>
</div>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="function">
<dt id="model.algorithms._utility.draw_nodes">
<code class="descclassname">model.algorithms._utility.</code><code class="descname">draw_nodes</code><span class="sig-paren">(</span><em>img</em>, <em>graph</em>, <em>radius=1</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms._utility.draw_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw all nodes on the input image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>img</em> : Input image where nodes are drawn</div>
<div class="line"><em>graph</em> : Input graph containing the nodes</div>
</div>
</dd>
<dt>Kwargs:</dt>
<dd><div class="first last line-block">
<div class="line"><em>radius</em> : Radius of drawn nodes</div>
</div>
</dd>
<dt>Returns:</dt>
<dd>Input image img with nodes drawn into it</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-model.algorithms.fast_nl_denoise_color">
<span id="fast-nl-denoise-color"></span><h2>fast_nl_denoise_color<a class="headerlink" href="#module-model.algorithms.fast_nl_denoise_color" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.fast_nl_denoise_color.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.fast_nl_denoise_color.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.fast_nl_denoise_color.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Fast nl Means Denoising Colored algorithm implementation.</p>
<dl class="method">
<dt id="model.algorithms.fast_nl_denoise_color.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.fast_nl_denoise_color.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.bilateral">
<span id="bilateral"></span><h2>bilateral<a class="headerlink" href="#module-model.algorithms.bilateral" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.bilateral.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.bilateral.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.bilateral.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Bilateral Filter algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.bilateral.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.bilateral.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Bilateral Filter algorithm from the opencv package to the
selected color channels of the current image.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>image</em> : image instance</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.smooth_degree_two_nodes">
<span id="smooth-degree-two-nodes"></span><h2>smooth_degree_two_nodes<a class="headerlink" href="#module-model.algorithms.smooth_degree_two_nodes" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.smooth_degree_two_nodes.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.smooth_degree_two_nodes.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.smooth_degree_two_nodes.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Smooth degree two nodes algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.smooth_degree_two_nodes.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.smooth_degree_two_nodes.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a filter which smooths nodes of degree two.
The edge attributes of the evolved edges are treated as follows:
Lengths are added to each other. The new edge length will be the sum of
the individual lengths.
Widths are combined using the mean. The new edge width will be the
mean of the individual widths.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>input</em> : A list which contains the image and the graph</div>
</div>
</dd>
<dt>Returns:</dt>
<dd><div class="first last line-block">
<div class="line"><em>graph</em> : A filtered networkx graph</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.otsus">
<span id="otsus"></span><h2>otsus<a class="headerlink" href="#module-model.algorithms.otsus" title="Permalink to this headline">¶</a></h2>
<p>(from opencv docs)
Otsu&#8217;s binarization automatically calculates a threshold value from image
histogram for a bimodal image. (For images which are not bimodal, binarization
won’t be accurate.)
For this, cv2.threshold() function is used with an extra flag, cv2.THRESH_OTSU.
For threshold value, simply pass zero. Then the algorithm finds the optimal
threshold value and returns you as the second output. If Otsu thresholding is
not used, the optimal threshold is same as the threshold value you used.</p>
<dl class="class">
<dt id="model.algorithms.otsus.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.otsus.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.otsus.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Otsu&#8217;s threshold implementation.</p>
<dl class="method">
<dt id="model.algorithms.otsus.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.otsus.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Otsu&#8217;s thresholding as described in opencv docs.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.watershed_dilation_erosion_otsu">
<span id="watershed-dilation-erosion-otsu"></span><h2>watershed_dilation_erosion_otsu<a class="headerlink" href="#module-model.algorithms.watershed_dilation_erosion_otsu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.watershed_dilation_erosion_otsu.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Watershed algorithm implementation with dilation, erosion and adaptive threshold marker.</p>
<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody.apply_mask_to_image">
<code class="descname">apply_mask_to_image</code><span class="sig-paren">(</span><em>mask</em>, <em>image</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody.apply_mask_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the segmented image based on the original image and the mask.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
mask: A mask containing foreground and background information</dd>
<dt>Returns:</dt>
<dd>A segmented image</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody.erosion_dilation_marker">
<code class="descname">erosion_dilation_marker</code><span class="sig-paren">(</span><em>image</em>, <em>erosion_iterations=2</em>, <em>dilation_iterations=1</em>, <em>threshold_strategy=&lt;function otsus_threshold&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody.erosion_dilation_marker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies morphological transformations to obtain the marker. The areas likely to be foreground
are obtained by erosion. The areas likely to be background are obtained by dilation.
The final marker is obtained by adding likely background to likely foreground where areas
not part of either are considered undecided.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>threshold_image: A properly thresholded image</dd>
<dt>Returns:</dt>
<dd>A marker subdividing image regions into likely foreground, likely background and undecided pixels</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody.otsus_threshold">
<code class="descname">otsus_threshold</code><span class="sig-paren">(</span><em>image</em>, <em>threshold_value=0</em>, <em>threshold_type=1L</em>, <em>**_</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody.otsus_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Watershed algorithm from the opencv package to the current
image with the help of marker based ob dilation, erosion and
adaptive threshold.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_otsu.AlgBody.watershed">
<code class="descname">watershed</code><span class="sig-paren">(</span><em>image</em>, <em>marker</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_otsu.AlgBody.watershed" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies opencv&#8217;s watershed method iteratively to an input image. An initial marker containing
preliminary information on which pixels are foreground serves as additional input.
The initial marker can be based on user input (color-picking), or can be constructed
with an automatic marker strategy. The marker decides from which pixels the flooding
in the watershed method may start. Finally, the marker is used to obtain a mask
classifying every pixel into foreground or background.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
marker: A marer suitable for use with opencv&#8217;s grabcut
iterations: The number of iterations grabcut may update the marker</dd>
<dt>Returns:</dt>
<dd>A mask image classifying every pixel into foreground or background</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.reduce_img">
<span id="reduce-img"></span><h2>reduce_img<a class="headerlink" href="#module-model.algorithms.reduce_img" title="Permalink to this headline">¶</a></h2>
<p>Tutorial Algorithm
Reduce image size using predefined ratio value.</p>
<dl class="class">
<dt id="model.algorithms.reduce_img.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.reduce_img.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.reduce_img.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>OpenCV image size reduction implementation</p>
<dl class="method">
<dt id="model.algorithms.reduce_img.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.reduce_img.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Args</dt>
<dd><a href="#id5"><span class="problematic" id="id6">|</span></a><em>img</em> (ndarray): image array</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.guo_hall">
<span id="guo-hall"></span><h2>guo_hall<a class="headerlink" href="#module-model.algorithms.guo_hall" title="Permalink to this headline">¶</a></h2>
<p>Thinning is the operation that takes a binary image and contracts the
foreground until only single-pixel wide lines remain. It is also known as
skeletonization.</p>
<p>The algorithm below was taken from NEFI1. It uses thinning C module written by
<a class="reference external" href="https://bitbucket.org/adrian_n/thinning">Adrian Neumann</a>.
The code was adapted for NEFI2.</p>
<dl class="class">
<dt id="model.algorithms.guo_hall.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.guo_hall.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.guo_hall.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Guo Hall thinning implementation.</p>
<dl class="method">
<dt id="model.algorithms.guo_hall.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.guo_hall.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Guo Hall thinning.
Use <code class="docutils literal"><span class="pre">`zhang_suen_node_detection()`</span></code> for node detection.
Use <code class="docutils literal"><span class="pre">`breadth_first_edge_detection()`</span></code> for edge detection.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="model.algorithms.guo_hall.breadth_first_edge_detection">
<code class="descclassname">model.algorithms.guo_hall.</code><code class="descname">breadth_first_edge_detection</code><span class="sig-paren">(</span><em>skel</em>, <em>segmented</em>, <em>graph</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.guo_hall.breadth_first_edge_detection" title="Permalink to this definition">¶</a></dt>
<dd><p>(from nefi1)
Detect edges in the skeletonized image.
Also compute the following edge properties:</p>
<blockquote>
<div><div class="line-block">
<div class="line"><em>pixels</em> : number of pixels on the edge in the skeleton</div>
<div class="line"><em>length</em> : length in pixels, horizontal/vertikal steps count 1,
diagonal steps count sqrt 2</div>
<div class="line"><em>width</em> : the mean diameter of the edge</div>
<div class="line"><em>width_var</em> : the variance of the width along the edge</div>
</div>
</div></blockquote>
<p>The runtime is linear in the number of pixels.
White pixels are <strong>much more</strong> expensive though.</p>
</dd></dl>

<dl class="function">
<dt id="model.algorithms.guo_hall.zhang_suen_node_detection">
<code class="descclassname">model.algorithms.guo_hall.</code><code class="descname">zhang_suen_node_detection</code><span class="sig-paren">(</span><em>skel</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.guo_hall.zhang_suen_node_detection" title="Permalink to this definition">¶</a></dt>
<dd><p>(from nefi1)
Node detection based on criteria put forward in &#8220;A fast parallel algorithm
for thinning digital patterns&#8221; by T. Y. Zhang and C. Y. Suen. Pixels p of
the skeleton are categorized as nodes/non-nodes based on the value of a
function A(p) depending on the pixel neighborhood of p. Please check the
above paper for details.</p>
<p>A(p1) == 1: The pixel p1 sits at the end of a skeleton line, thus a node
of degree 1 has been found.
A(p1) == 2: The pixel p1 sits in the middel of a skeleton line but not at
a branching point, thus a node of degree 2 has been found. Such nodes are
ignored and not introduced to the graph.
A(p1) &gt;= 3: The pixel p1 belongs to a branching point of a skeleton line,
thus a node of degree &gt;=3 has been found.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt><em>skel</em> <span class="classifier-delimiter">:</span> <span class="classifier">Skeletonised source image. The skeleton must be exactly 1</span></dt>
<dd>pixel wide.</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><em>graph</em> : networkx Graph object with detected nodes.</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-model.algorithms.watershed_dilation_erosion_adaptive">
<span id="watershed-dilation-erosion-adaptive"></span><h2>watershed_dilation_erosion_adaptive<a class="headerlink" href="#module-model.algorithms.watershed_dilation_erosion_adaptive" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.watershed_dilation_erosion_adaptive.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Watershed algorithm implementation with dilation, erosion and adaptive threshold marker.</p>
<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.adaptive_threshold">
<code class="descname">adaptive_threshold</code><span class="sig-paren">(</span><em>image</em>, <em>threshold_value=255</em>, <em>threshold_type=1L</em>, <em>adaptive_type=0L</em>, <em>block_size=11</em>, <em>constant=2</em>, <em>**_</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.adaptive_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.apply_mask_to_image">
<code class="descname">apply_mask_to_image</code><span class="sig-paren">(</span><em>mask</em>, <em>image</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.apply_mask_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the segmented image based on the original image and the mask.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
mask: A mask containing foreground and background information</dd>
<dt>Returns:</dt>
<dd>A segmented image</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.erosion_dilation_marker">
<code class="descname">erosion_dilation_marker</code><span class="sig-paren">(</span><em>image</em>, <em>erosion_iterations=2</em>, <em>dilation_iterations=1</em>, <em>threshold_strategy=&lt;function adaptive_threshold&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.erosion_dilation_marker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies morphological transformations to obtain the marker. The areas likely to be foreground
are obtained by erosion. The areas likely to be background are obtained by dilation.
The final marker is obtained by adding likely background to likely foreground where areas
not part of either are considered undecided.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>threshold_image: A properly thresholded image</dd>
<dt>Returns:</dt>
<dd>A marker subdividing image regions into likely foreground, likely background and undecided pixels</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the Watershed algorithm from the opencv package to the current
image with the help of marker based ob dilation, erosion and
adaptive threshold.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.watershed">
<code class="descname">watershed</code><span class="sig-paren">(</span><em>image</em>, <em>marker</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.watershed_dilation_erosion_adaptive.AlgBody.watershed" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies opencv&#8217;s watershed method iteratively to an input image. An initial marker containing
preliminary information on which pixels are foreground serves as additional input.
The initial marker can be based on user input (color-picking), or can be constructed
with an automatic marker strategy. The marker decides from which pixels the flooding
in the watershed method may start. Finally, the marker is used to obtain a mask
classifying every pixel into foreground or background.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>image: An input image which is not altered
marker: A marer suitable for use with opencv&#8217;s grabcut
iterations: The number of iterations grabcut may update the marker</dd>
<dt>Returns:</dt>
<dd>A mask image classifying every pixel into foreground or background</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.color_enchance">
<span id="color-enchance"></span><h2>color_enchance<a class="headerlink" href="#module-model.algorithms.color_enchance" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.color_enchance.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.color_enchance.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.color_enchance.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Color enhancement algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.color_enchance.AlgBody.compute_channels">
<code class="descname">compute_channels</code><span class="sig-paren">(</span><em>image_channel</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.color_enchance.AlgBody.compute_channels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="model.algorithms.color_enchance.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.color_enchance.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model.algorithms.invert_color">
<span id="invert-color"></span><h2>invert_color<a class="headerlink" href="#module-model.algorithms.invert_color" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="model.algorithms.invert_color.AlgBody">
<em class="property">class </em><code class="descclassname">model.algorithms.invert_color.</code><code class="descname">AlgBody</code><a class="headerlink" href="#model.algorithms.invert_color.AlgBody" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="subsection3.html#model.algorithms._alg.Algorithm" title="model.algorithms._alg.Algorithm"><code class="xref py py-class docutils literal"><span class="pre">model.algorithms._alg.Algorithm</span></code></a></p>
<p>Invert Color algorithm implementation</p>
<dl class="method">
<dt id="model.algorithms.invert_color.AlgBody.process">
<code class="descname">process</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#model.algorithms.invert_color.AlgBody.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Invert the current image</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><div class="first last line-block">
<div class="line"><em>args</em> : a list of arguments, e.g. image ndarray</div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Andreas Firczynski, Dennis Groß, Martino Bruni, Pavel Shkadzko, Philipp Reichert, Sebastian Schattner.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'2.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>